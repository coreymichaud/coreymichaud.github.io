{
  "hash": "1e279692d900d43e5e02029ba1dddfd3",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Alzheimer's Detection\" # This is the title of the blog post\ndescription: \"This is a python notebook where I analyze the DAWRIN dataset to detect Alzheimer's in an individual's handwriting. To classify, I used random forest in Python.\" # This is the description and shows up under the title and picture on the blog page\nauthor: # Use this for information about myself\n  - name: Corey Michaud\ndate: 06-31-2023 # Date this post is published\ncategories: [Python, Machine Learning] # Self-defined categories\nimage: \"/projects/thumbnails/python.png\" # This is the image that will be the preview image and it HAS to be in this file to work\njupyter: python3\n---\n\n\n\n\n\n<!-- This is the github button -->\n\n<a href=\"https://github.com/coreymichaud/Alzheimers-Detection\" class=\"btn\" target=\"_blank\"><i class=\"fab fa-github\"></i> Source Code</a>\n\n# Background\n\nAlzheimer's is a type of dementia that affects memory, thinking, and behavior. It is caused by increasing age, and primarily affects people above the age of 65. As a person develops Alzheimer's, it progressively becomes worse where the individual can lose the ability to carry a conversation or even take care of themselves. After diagnosis, a person can expect to live on average between 4 to 8 years, but on better cases up to 20 years. Luckily there is medication to help slow the worsening of Alzheimer's, but nothing to completely prevent it from happening.\n\nThe data used for the detection of Alzheimer's through handwriting comes from the DARWIN (Diagnosis AlzheimeR WIth haNdwriting) dataset. This dataset is made up of 174 individual's handwriting where roughly half are Alzheimer's patients (P), and healthy people (H). The handwriting was taken through tasks the individuals were asked to do, and then variables like time in air were measured. In doing so, the creators of the DARWIN dataset provided us the materials we need to use machine learning techniques to detect the early stages of Alzheimer's through handwriting. Some of the tasks recorded were connecting points through lines and copying phrases that were written in front of them, all of which test different parts of the brain.\n\nUsing handwriting data, I will use a random forest classifier to predict whether an individual has Alzheimer's or not. The goal is for future handwriting data to be inserted and accurately predict the correct diagnosis, saving the individual time to get treatment to slow down the process.\n\nAlzheimers detection dataset obtained from https://www.kaggle.com/datasets/taeefnajib/handwriting-data-to-detect-alzheimers-disease.\n\n::: {#8562b780 .cell execution_count=1}\n``` {.python .cell-code}\n# Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n```\n:::\n\n\n::: {#690f61cf .cell execution_count=2}\n``` {.python .cell-code}\n# Loading data\nalz = pd.read_csv(\"alzheimers.csv\")\n```\n:::\n\n\n# Exploratory Data Analysis\n\n::: {#8d565a3c .cell execution_count=3}\n``` {.python .cell-code}\n# First 5 rows of data\nalz.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>air_time1</th>\n      <th>disp_index1</th>\n      <th>gmrt_in_air1</th>\n      <th>gmrt_on_paper1</th>\n      <th>max_x_extension1</th>\n      <th>max_y_extension1</th>\n      <th>mean_acc_in_air1</th>\n      <th>mean_acc_on_paper1</th>\n      <th>mean_gmrt1</th>\n      <th>...</th>\n      <th>mean_jerk_in_air25</th>\n      <th>mean_jerk_on_paper25</th>\n      <th>mean_speed_in_air25</th>\n      <th>mean_speed_on_paper25</th>\n      <th>num_of_pendown25</th>\n      <th>paper_time25</th>\n      <th>pressure_mean25</th>\n      <th>pressure_var25</th>\n      <th>total_time25</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id_1</td>\n      <td>5160</td>\n      <td>0.000013</td>\n      <td>120.804174</td>\n      <td>86.853334</td>\n      <td>957</td>\n      <td>6601</td>\n      <td>0.361800</td>\n      <td>0.217459</td>\n      <td>103.828754</td>\n      <td>...</td>\n      <td>0.141434</td>\n      <td>0.024471</td>\n      <td>5.596487</td>\n      <td>3.184589</td>\n      <td>71</td>\n      <td>40120</td>\n      <td>1749.278166</td>\n      <td>296102.7676</td>\n      <td>144605</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id_2</td>\n      <td>51980</td>\n      <td>0.000016</td>\n      <td>115.318238</td>\n      <td>83.448681</td>\n      <td>1694</td>\n      <td>6998</td>\n      <td>0.272513</td>\n      <td>0.144880</td>\n      <td>99.383459</td>\n      <td>...</td>\n      <td>0.049663</td>\n      <td>0.018368</td>\n      <td>1.665973</td>\n      <td>0.950249</td>\n      <td>129</td>\n      <td>126700</td>\n      <td>1504.768272</td>\n      <td>278744.2850</td>\n      <td>298640</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id_3</td>\n      <td>2600</td>\n      <td>0.000010</td>\n      <td>229.933997</td>\n      <td>172.761858</td>\n      <td>2333</td>\n      <td>5802</td>\n      <td>0.387020</td>\n      <td>0.181342</td>\n      <td>201.347928</td>\n      <td>...</td>\n      <td>0.178194</td>\n      <td>0.017174</td>\n      <td>4.000781</td>\n      <td>2.392521</td>\n      <td>74</td>\n      <td>45480</td>\n      <td>1431.443492</td>\n      <td>144411.7055</td>\n      <td>79025</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id_4</td>\n      <td>2130</td>\n      <td>0.000010</td>\n      <td>369.403342</td>\n      <td>183.193104</td>\n      <td>1756</td>\n      <td>8159</td>\n      <td>0.556879</td>\n      <td>0.164502</td>\n      <td>276.298223</td>\n      <td>...</td>\n      <td>0.113905</td>\n      <td>0.019860</td>\n      <td>4.206746</td>\n      <td>1.613522</td>\n      <td>123</td>\n      <td>67945</td>\n      <td>1465.843329</td>\n      <td>230184.7154</td>\n      <td>181220</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id_5</td>\n      <td>2310</td>\n      <td>0.000007</td>\n      <td>257.997131</td>\n      <td>111.275889</td>\n      <td>987</td>\n      <td>4732</td>\n      <td>0.266077</td>\n      <td>0.145104</td>\n      <td>184.636510</td>\n      <td>...</td>\n      <td>0.121782</td>\n      <td>0.020872</td>\n      <td>3.319036</td>\n      <td>1.680629</td>\n      <td>92</td>\n      <td>37285</td>\n      <td>1841.702561</td>\n      <td>158290.0255</td>\n      <td>72575</td>\n      <td>P</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 452 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#382e57e5 .cell execution_count=4}\n``` {.python .cell-code}\n# Shape of data\nalz.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n(174, 452)\n```\n:::\n:::\n\n\n::: {#cfb7a807 .cell execution_count=5}\n``` {.python .cell-code}\n# Data information\nalz.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 174 entries, 0 to 173\nColumns: 452 entries, ID to class\ndtypes: float64(300), int64(150), object(2)\nmemory usage: 614.6+ KB\n```\n:::\n:::\n\n\n::: {#ab06bd32 .cell execution_count=6}\n``` {.python .cell-code}\n# Checking for object column names\nalz.select_dtypes(include = \"object\").columns.tolist()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n['ID', 'class']\n```\n:::\n:::\n\n\n::: {#f02b9896 .cell execution_count=7}\n``` {.python .cell-code}\n# Checking for missing values\nalz.isna().sum() # No NA values\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\nID                 0\nair_time1          0\ndisp_index1        0\ngmrt_in_air1       0\ngmrt_on_paper1     0\n                  ..\npaper_time25       0\npressure_mean25    0\npressure_var25     0\ntotal_time25       0\nclass              0\nLength: 452, dtype: int64\n```\n:::\n:::\n\n\n# Feature Engineering\n\n::: {#7a138cf3 .cell execution_count=8}\n``` {.python .cell-code}\n# Removing ID column\nalz = alz.drop(\"ID\", axis = 1)\nalz.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>air_time1</th>\n      <th>disp_index1</th>\n      <th>gmrt_in_air1</th>\n      <th>gmrt_on_paper1</th>\n      <th>max_x_extension1</th>\n      <th>max_y_extension1</th>\n      <th>mean_acc_in_air1</th>\n      <th>mean_acc_on_paper1</th>\n      <th>mean_gmrt1</th>\n      <th>mean_jerk_in_air1</th>\n      <th>...</th>\n      <th>mean_jerk_in_air25</th>\n      <th>mean_jerk_on_paper25</th>\n      <th>mean_speed_in_air25</th>\n      <th>mean_speed_on_paper25</th>\n      <th>num_of_pendown25</th>\n      <th>paper_time25</th>\n      <th>pressure_mean25</th>\n      <th>pressure_var25</th>\n      <th>total_time25</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5160</td>\n      <td>0.000013</td>\n      <td>120.804174</td>\n      <td>86.853334</td>\n      <td>957</td>\n      <td>6601</td>\n      <td>0.361800</td>\n      <td>0.217459</td>\n      <td>103.828754</td>\n      <td>0.051836</td>\n      <td>...</td>\n      <td>0.141434</td>\n      <td>0.024471</td>\n      <td>5.596487</td>\n      <td>3.184589</td>\n      <td>71</td>\n      <td>40120</td>\n      <td>1749.278166</td>\n      <td>296102.7676</td>\n      <td>144605</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>51980</td>\n      <td>0.000016</td>\n      <td>115.318238</td>\n      <td>83.448681</td>\n      <td>1694</td>\n      <td>6998</td>\n      <td>0.272513</td>\n      <td>0.144880</td>\n      <td>99.383459</td>\n      <td>0.039827</td>\n      <td>...</td>\n      <td>0.049663</td>\n      <td>0.018368</td>\n      <td>1.665973</td>\n      <td>0.950249</td>\n      <td>129</td>\n      <td>126700</td>\n      <td>1504.768272</td>\n      <td>278744.2850</td>\n      <td>298640</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2600</td>\n      <td>0.000010</td>\n      <td>229.933997</td>\n      <td>172.761858</td>\n      <td>2333</td>\n      <td>5802</td>\n      <td>0.387020</td>\n      <td>0.181342</td>\n      <td>201.347928</td>\n      <td>0.064220</td>\n      <td>...</td>\n      <td>0.178194</td>\n      <td>0.017174</td>\n      <td>4.000781</td>\n      <td>2.392521</td>\n      <td>74</td>\n      <td>45480</td>\n      <td>1431.443492</td>\n      <td>144411.7055</td>\n      <td>79025</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2130</td>\n      <td>0.000010</td>\n      <td>369.403342</td>\n      <td>183.193104</td>\n      <td>1756</td>\n      <td>8159</td>\n      <td>0.556879</td>\n      <td>0.164502</td>\n      <td>276.298223</td>\n      <td>0.090408</td>\n      <td>...</td>\n      <td>0.113905</td>\n      <td>0.019860</td>\n      <td>4.206746</td>\n      <td>1.613522</td>\n      <td>123</td>\n      <td>67945</td>\n      <td>1465.843329</td>\n      <td>230184.7154</td>\n      <td>181220</td>\n      <td>P</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2310</td>\n      <td>0.000007</td>\n      <td>257.997131</td>\n      <td>111.275889</td>\n      <td>987</td>\n      <td>4732</td>\n      <td>0.266077</td>\n      <td>0.145104</td>\n      <td>184.636510</td>\n      <td>0.037528</td>\n      <td>...</td>\n      <td>0.121782</td>\n      <td>0.020872</td>\n      <td>3.319036</td>\n      <td>1.680629</td>\n      <td>92</td>\n      <td>37285</td>\n      <td>1841.702561</td>\n      <td>158290.0255</td>\n      <td>72575</td>\n      <td>P</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 451 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#6d95bb19 .cell execution_count=9}\n``` {.python .cell-code}\n# Converting class to numeric\nalz[\"class\"] = alz[\"class\"].replace({'P': 1, 'H': 0})\nalz[\"class\"]\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\cor3y\\AppData\\Local\\Temp\\ipykernel_11244\\2961317950.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  alz[\"class\"] = alz[\"class\"].replace({'P': 1, 'H': 0})\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n0      1\n1      1\n2      1\n3      1\n4      1\n      ..\n169    0\n170    0\n171    0\n172    0\n173    0\nName: class, Length: 174, dtype: int64\n```\n:::\n:::\n\n\n# Model Training\n\n::: {#163d40b2 .cell execution_count=10}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\n# Separating features from target\nX = alz.drop(columns=[\"class\"])\ny = alz[\"class\"]\n\n# Training data with a 70/30 split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state = 42)\n```\n:::\n\n\n::: {#5ac5b782 .cell execution_count=11}\n``` {.python .cell-code}\n# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import plot_tree\n\n# Creating random forest pipeline with scaled data\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('classifier', RandomForestClassifier(random_state = 42, max_samples = 0.6, min_samples_leaf = 2))\n])\n\n# Fitting pipeline\npipe.fit(X_train, y_train)\n\n# Predicting target values\ny_pred = pipe.predict(X_test)\n```\n:::\n\n\n::: {#5fe265b2 .cell execution_count=12}\n``` {.python .cell-code}\n# Plotting first tree in the random forest\ntree_viz = pipe.named_steps['classifier'].estimators_[0]\n\nfig, ax = plt.subplots(figsize = (15, 10))\n\nplot_tree(tree_viz, feature_names = alz.columns.tolist(), class_names = [\"Patient\", \"Healthy\"], filled = True)\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-1.png){width=1135 height=758}\n:::\n:::\n\n\n::: {#161e9bf1 .cell execution_count=13}\n``` {.python .cell-code}\n# Plotting fiftieth tree in the random forest\ntree_viz = pipe.named_steps['classifier'].estimators_[49]\n\nfig, ax = plt.subplots(figsize = (15, 10))\n\nplot_tree(tree_viz, feature_names = alz.columns.tolist(), class_names = [\"Patient\", \"Healthy\"], filled = True)\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-14-output-1.png){width=1135 height=758}\n:::\n:::\n\n\n# Results\n\n::: {#c43d6c05 .cell execution_count=14}\n``` {.python .cell-code}\nfrom sklearn.metrics import f1_score\n\n# F1 score is high so this random forest model is a good predictor of the target\nf1 = f1_score(y_test, y_pred)\nprint(\"F1 Score:\", f1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nF1 Score: 0.9019607843137255\n```\n:::\n:::\n\n\n::: {#3fea4c9e .cell execution_count=15}\n``` {.python .cell-code}\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\n# False positive and true positive rates\nfpr, tpr, _ = roc_curve(y_test, y_pred)\n\n# AUC\nauc = roc_auc_score(y_test, y_pred)\n\n# Plotting ROC curve\nfig, ax = plt.subplots()\n\nax.plot(fpr, tpr, color = 'darkorange', lw = 2, label = 'ROC curve (AUC = {:.2f})'.format(auc))\nax.plot([0, 1], [0, 1], color = 'navy', lw = 2, linestyle = '--')\n\nax.set_xlim([0.0, 1.0])\nax.set_ylim([0.0, 1.05])\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.set_title('Receiver Operating Characteristic (ROC) Curve')\nax.legend(loc = \"lower right\")\n\nsns.despine()\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-16-output-1.png){width=599 height=449}\n:::\n:::\n\n\n::: {#be6ca198 .cell execution_count=16}\n``` {.python .cell-code}\nfrom sklearn.metrics import confusion_matrix\n\n# Creating confusion matrix\nconf_matrix = confusion_matrix(y_test,y_pred)\n\n# Plotting confusion matrix \nfig, ax = plt.subplots()\n\nsns.heatmap(conf_matrix,\n            annot = True,\n            fmt = 'g',\n            xticklabels = ['Positive', 'Negative'],\n            yticklabels = ['Positive', 'Negative'],\n            cmap = [\"Red\", \"Green\", \"Red\", \"Green\"],\n            cbar = False,\n            annot_kws = {\"size\": 20},\n            ax = ax)\n\nax.set_title('Confusion Matrix', fontsize = 17)\nax.set_ylabel('Prediction', fontsize = 13)\nax.set_xlabel('Actual', fontsize = 13)\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-17-output-1.png){width=585 height=458}\n:::\n:::\n\n\n::: {#5058920f .cell execution_count=17}\n``` {.python .cell-code}\n# Creating TP/FP/TN/FN\nTP = conf_matrix[1, 1]\nFN = conf_matrix[1, 0]\nTN = conf_matrix[0, 0]\nFP = conf_matrix[0, 1]\n\n# Printing results of predictions\naccuracy = (TP + TN) / (TP + TN + FP + FN)\nprecision = (TP) / (TP + FP)\nsensitivity = TP / (TP + FN)\nspecificity = TN / (TN + FP)\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Sensitivity:\", sensitivity)\nprint(\"Specificity:\", specificity)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy: 0.9056603773584906\nPrecision: 0.8846153846153846\nSensitivity: 0.92\nSpecificity: 0.8928571428571429\n```\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}