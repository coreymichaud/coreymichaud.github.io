<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>**Corey Michaud**</title>
<link>https://coreymichaud.github.io/blog.html</link>
<atom:link href="https://coreymichaud.github.io/blog.xml" rel="self" type="application/rss+xml"/>
<description>Corey Michaud&#39;s Portfolio</description>
<generator>quarto-1.5.47</generator>
<lastBuildDate>Wed, 24 Jul 2024 04:00:00 GMT</lastBuildDate>
<item>
  <title>Text Preprocessing for NLP</title>
  <dc:creator>Corey Michaud</dc:creator>
  <link>https://coreymichaud.github.io/blog/Text-Preprocessing-NLP/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Natural language processing (NLP) is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and human language. It is used for things like sentiment analysis, product reviews, text summary, text generation, language translation, and countless more. Essentially, if you want to solve an issue that involves natural language, it’s an NLP problem.</p>
<p>The early days of NLP involved a bunch of scientists creating if-else statements to support a large set of rules, so it was very limited on what you can accomplish. Since then, AI has come a long way and we can now use neural networks, like a recurrent neural network (RNN), to work with text data. Luckily for us, frameworks like <code>TensorFlow</code> and <code>PyTorch</code> allow us to easily create these types of models where they can learn from text data and produce whatever we’re looking for. Most people use python for deep learning, so any code mentioned will be python. Some popular libraries for NLP in python are <code>NLTK</code> (Natural Language Tool Kit) which is used for cleaning text data and applying some attributes mentioned later, and <code>TensorFlow</code> for the actual model creation. <code>TensorFlow</code> in this post’s case is used for tokenization, and some other languages get used for smaller parts like <code>spacy</code>, <code>re</code>, <code>spellchecker</code>, and <code>collections.</code></p>
<p>When you want to create a neural network to run an NLP task, like a Long Short-Term Memory (LSTM) recurrent neural network, you have to clean the text for the computer to be able to find patterns in the first place. When using something like a transformer such as GPT-4 or BERT, most of the text preprocessing is done in the model so it won’t be necessary to clean yourself, but the techniques mentioned bellow assume you want to know how to preprocess text data for non-transformer based models. Text preprocessing usually involves cleaning, tokenizing (breaking sentences into words), and embedding (representing words as vectors where similar words are closer together numerically).</p>
</section>
<section id="text-cleaning" class="level1">
<h1>Text Cleaning</h1>
<p>Text cleaning is the process of preparing your text before converting words into numerical representations for your model to find patterns. The primary goal is to ensure that different forms of the same word are treated as equal. For example, “long,” “Long,” and “Looong” should all be recognized as “long” by the computer. This section outlines the fundamental steps to achieve a normalized dataset, which you can adjust based on your specific needs.</p>
<section id="lowercasing" class="level2">
<h2 class="anchored" data-anchor-id="lowercasing">Lowercasing</h2>
<p>Convert all text to lowercase to avoid treating something like “Hot” and “hot” as different words.</p>
<p>Python Example:</p>
<div id="e5414fa0" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> lowercase(text):</span>
<span id="cb1-2">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> text.lower()</span></code></pre></div>
</div>
</section>
<section id="urls" class="level2">
<h2 class="anchored" data-anchor-id="urls">URLs</h2>
<p>Remove URLs to retain only the text.</p>
<p>Python Example:</p>
<div id="5148e07d" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> re</span>
<span id="cb2-2"></span>
<span id="cb2-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> remove_urls(text):</span>
<span id="cb2-4">    url_pattern <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> re.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>(<span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'https?://\S+|www\.\S+'</span>)</span>
<span id="cb2-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> url_pattern.sub(<span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r''</span>, text)</span></code></pre></div>
</div>
</section>
<section id="emoticons" class="level2">
<h2 class="anchored" data-anchor-id="emoticons">Emoticons</h2>
<p>Remove emoticons and emojis, as they do not convey meaning to the computer in the same way words do</p>
<p>Python Example:</p>
<div id="edca9206" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> re</span>
<span id="cb3-2"></span>
<span id="cb3-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> remove_emoticons(text):</span>
<span id="cb3-4">  emoji_pattern <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> re.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"["</span></span>
<span id="cb3-5">                           <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">u"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\U0001F600</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\U0001F64F</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># emoticons</span></span>
<span id="cb3-6">                           <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">u"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\U0001F300</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\U0001F5FF</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># symbols &amp; pictographs</span></span>
<span id="cb3-7">                           <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">u"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\U0001F680</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\U0001F6FF</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># transport &amp; map symbols</span></span>
<span id="cb3-8">                           <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">u"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\U0001F1E0</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\U0001F1FF</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># flags (iOS)</span></span>
<span id="cb3-9">                           <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">u"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\U00002702</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\U000027B0</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb3-10">                           <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">u"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\U000024C2</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\U0001F251</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb3-11">                           <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"]+"</span>, flags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>re.UNICODE)</span>
<span id="cb3-12">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> emoji_pattern.sub(<span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r''</span>, text)</span></code></pre></div>
</div>
</section>
<section id="special-characters-numbers" class="level2">
<h2 class="anchored" data-anchor-id="special-characters-numbers">Special Characters &amp; Numbers</h2>
<p>Remove special characters and numbers, unless they are relevant to your analysis.</p>
<p>Python Example:</p>
<div id="32db615e" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> re</span>
<span id="cb4-2"></span>
<span id="cb4-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> remove_characters(text):</span>
<span id="cb4-4">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> re.sub(<span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'[^A-Za-z ]+'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>, text)</span></code></pre></div>
</div>
</section>
<section id="stop-words" class="level2">
<h2 class="anchored" data-anchor-id="stop-words">Stop Words</h2>
<p>Remove stop words, which are common words that do not contribute much to the meaning.</p>
<p>Python Example:</p>
<div id="14bd2803" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> nltk.corpus <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> stopwords</span>
<span id="cb5-2">nltk.download(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'stopwords'</span>)</span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> remove_stopwords(text):</span>
<span id="cb5-5">    stop_words <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(stopwords.words(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"english"</span>))</span>
<span id="cb5-6">    words <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text.split()</span>
<span id="cb5-7">    filtered_words <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [word <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> word <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> words <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> word.lower() <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> stop_words]</span>
<span id="cb5-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">' '</span>.join(filtered_words)</span></code></pre></div>
</div>
</section>
<section id="spell-correction" class="level2">
<h2 class="anchored" data-anchor-id="spell-correction">Spell Correction</h2>
<p>Correct spelling mistakes to ensure consistency in word representation.</p>
<p>Python Example:</p>
<div id="d63cd6c7" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> spellchecker <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SpellChecker</span>
<span id="cb6-2"></span>
<span id="cb6-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> correct_spellings(text):</span>
<span id="cb6-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> text.strip():</span>
<span id="cb6-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> text</span>
<span id="cb6-6"></span>
<span id="cb6-7">    spell <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SpellChecker()</span>
<span id="cb6-8">    corrected_text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb6-9">    misspelled_words <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> spell.unknown(text.split())</span>
<span id="cb6-10"></span>
<span id="cb6-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> word <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> text.split():</span>
<span id="cb6-12">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> word <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> misspelled_words:</span>
<span id="cb6-13">            suggested_correction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> spell.correction(word)</span>
<span id="cb6-14">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> suggested_correction <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"'"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> suggested_correction:</span>
<span id="cb6-15">                corrected_text.append(suggested_correction)</span>
<span id="cb6-16">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb6-17">                corrected_text.append(word)</span>
<span id="cb6-18">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb6-19">            corrected_text.append(word)</span>
<span id="cb6-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">" "</span>.join(corrected_text)</span></code></pre></div>
</div>
</section>
<section id="part-of-speech" class="level2">
<h2 class="anchored" data-anchor-id="part-of-speech">Part-of-Speech</h2>
<p>Tag each word with its part of speech to provide context to the model.</p>
<p>Python Example:</p>
<div id="edf91d33" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> nltk</span>
<span id="cb7-2">nltk.download(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'averaged_perceptron_tagger'</span>)</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_wordnet_pos(text):</span>
<span id="cb7-5">    tag <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nltk.pos_tag([text])[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].upper()</span>
<span id="cb7-6">    tag_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"J"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adjective</span></span>
<span id="cb7-7">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"N"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"n"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Noun</span></span>
<span id="cb7-8">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"V"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"v"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Verb</span></span>
<span id="cb7-9">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"R"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"r"</span>}  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adverb</span></span>
<span id="cb7-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> tag_dict.get(tag, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"n"</span>)</span></code></pre></div>
</div>
</section>
<section id="lemmatizing-vs-stemming" class="level2">
<h2 class="anchored" data-anchor-id="lemmatizing-vs-stemming">Lemmatizing vs Stemming</h2>
<p>Once you’ve made it this far, should you lemmatize or stem your words? Lemmatization is when you cut the suffix off a word and replace it with the normalized form of the word, while stemming refers to cutting the suffix off completely. A good example of this is if you have the word “running”, the stemmed version would be “runn” while the lemmatized version would be “run”. You can see that by lemmatizing your words, you convert it into it’s root word, while stemming could create almost like a second version of the word, which your model might see as a completely separate word. This is why I highly suggest <strong>lemmatizing</strong> your words rather than stemming them.</p>
<p>Python Example:</p>
<div id="74a312ce" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> nltk.stem <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> WordNetLemmatizer</span>
<span id="cb8-2">nltk.download(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'punkt'</span>)</span>
<span id="cb8-3">nltk.download(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'wordnet'</span>)</span>
<span id="cb8-4"></span>
<span id="cb8-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> lemmatize(text):</span>
<span id="cb8-6">    lemmatizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> WordNetLemmatizer()</span>
<span id="cb8-7">    lemmatized_words <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [lemmatizer.lemmatize(word, get_wordnet_pos(word)) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> word <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> nltk.word_tokenize(text)]</span>
<span id="cb8-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">" "</span>.join(lemmatized_words)</span></code></pre></div>
</div>
</section>
<section id="other-options" class="level2">
<h2 class="anchored" data-anchor-id="other-options">Other Options</h2>
<p>There is more out there that you can do to clean or preprocess your text data. Some examples could be marking negations, handling specific elements like hashtags, converting dates to the same format, converting numbers to words, etc. Some of the cleaning mentioned before you could possibly even avoid, depending on what your end goal is. If you’re planning on using a transformer in the future, pretty much all this text preprocessing is done fully for you through pre-trained models which would cut a lot of time from this stage.</p>
</section>
</section>
<section id="tokenization" class="level1">
<h1>Tokenization</h1>
<p>After cleaning, split sentences into words (tokens), create sequences, and pad them to ensure consistent vector lengths.</p>
<div id="f7d63c4b" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tensorflow.keras.preprocessing.text <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Tokenizer</span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> tensorflow.keras.preprocessing.sequence <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pad_sequences</span>
<span id="cb9-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb9-4"></span>
<span id="cb9-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define parameters</span></span>
<span id="cb9-6">MAX_VOCAB_SIZE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> max_vocab_size  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Maximum number of words to keep in the vocabulary</span></span>
<span id="cb9-7">MAX_SEQUENCE_LENGTH <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> max_seq_length  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Maximum length of each sequence</span></span>
<span id="cb9-8"></span>
<span id="cb9-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assuming you have these variables defined:</span></span>
<span id="cb9-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># all_texts: list of all text samples</span></span>
<span id="cb9-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># train_texts, val_texts, test_texts: lists of text samples for each set</span></span>
<span id="cb9-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># train_labels, val_labels, test_labels: corresponding labels</span></span>
<span id="cb9-13"></span>
<span id="cb9-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Tokenization</span></span>
<span id="cb9-15">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Tokenizer(num_words<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>MAX_VOCAB_SIZE)</span>
<span id="cb9-16">tokenizer.fit_on_texts(all_texts)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fit tokenizer on all available texts</span></span>
<span id="cb9-17"></span>
<span id="cb9-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert texts to sequences</span></span>
<span id="cb9-19">train_sequences <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer.texts_to_sequences(train_texts)</span>
<span id="cb9-20">val_sequences <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer.texts_to_sequences(val_texts)</span>
<span id="cb9-21">test_sequences <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer.texts_to_sequences(test_texts)</span>
<span id="cb9-22"></span>
<span id="cb9-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pad sequences</span></span>
<span id="cb9-24">train_padded <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pad_sequences(train_sequences, maxlen<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>MAX_SEQUENCE_LENGTH, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'post'</span>)</span>
<span id="cb9-25">val_padded <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pad_sequences(val_sequences, maxlen<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>MAX_SEQUENCE_LENGTH, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'post'</span>)</span>
<span id="cb9-26">test_padded <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pad_sequences(test_sequences, maxlen<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>MAX_SEQUENCE_LENGTH, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'post'</span>)</span>
<span id="cb9-27"></span>
<span id="cb9-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Convert labels to numpy arrays</span></span>
<span id="cb9-29">train_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array(train_labels)</span>
<span id="cb9-30">val_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array(val_labels)</span>
<span id="cb9-31">test_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array(test_labels)</span>
<span id="cb9-32"></span>
<span id="cb9-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Now train_padded, val_padded, and test_padded are your vectorized inputs</span></span>
<span id="cb9-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># train_labels, val_labels, and test_labels are your corresponding labels</span></span></code></pre></div>
</details>
</div>
</section>
<section id="pre-trained-embeddings" class="level1">
<h1>Pre-trained Embeddings</h1>
<p>The final part of text preprocessing are embeddings. Realistically, unless you have a crazy compute power, you’re not going to be training your own embeddings, so you can use something like <a href="https://nlp.stanford.edu/projects/glove/">GloVe</a>, <a href="https://arxiv.org/abs/1301.3781">Word2Vec</a>, or others like these where people have embedded lots of words to find their spatial relationships to each other. Below I have an example of GloVe, and it would create the vector representations of your words you’ve just cleaned, and tokenized, and make it ready to put into your deep learning model.</p>
<p>If in the future you are planning on using a pre-trained model like BERT or GPT, then you would not need to do this step as the model will already do all the work for you.</p>
<div id="ecdb5b96" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb10-2"></span>
<span id="cb10-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> load_glove_embeddings(filepath, word_index, embedding_dim):</span>
<span id="cb10-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb10-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Load GloVe embeddings for the words in the tokenizer's word index.</span></span>
<span id="cb10-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb10-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb10-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    filepath (str): Path to the GloVe embeddings file.</span></span>
<span id="cb10-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    word_index (dict): Word-to-index mapping from the tokenizer.</span></span>
<span id="cb10-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    embedding_dim (int): Dimensionality of the GloVe embeddings.</span></span>
<span id="cb10-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb10-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Returns:</span></span>
<span id="cb10-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    numpy.ndarray: Embedding matrix for the vocabulary.</span></span>
<span id="cb10-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb10-15">    vocab_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(word_index) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Adding 1 for padding token</span></span>
<span id="cb10-16">    embedding_matrix <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((vocab_size, embedding_dim))</span>
<span id="cb10-17">    </span>
<span id="cb10-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(filepath, encoding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"utf8"</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> f:</span>
<span id="cb10-19">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> line <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> f:</span>
<span id="cb10-20">            values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> line.split()</span>
<span id="cb10-21">            word <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> values[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb10-22">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> word <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> word_index:</span>
<span id="cb10-23">                idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> word_index[word]</span>
<span id="cb10-24">                embedding_matrix[idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.asarray(values[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:], dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'float32'</span>)</span>
<span id="cb10-25">    </span>
<span id="cb10-26">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> embedding_matrix</span>
<span id="cb10-27"></span>
<span id="cb10-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Example usage:</span></span>
<span id="cb10-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assuming you have already created and fitted a tokenizer</span></span>
<span id="cb10-30">GLOVE_PATH <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'path/to/glove.42B.300d.txt'</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update this path</span></span>
<span id="cb10-31">EMBEDDING_DIM <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span></span>
<span id="cb10-32"></span>
<span id="cb10-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load GloVe embeddings</span></span>
<span id="cb10-34">embedding_matrix <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_glove_embeddings(GLOVE_PATH, tokenizer.word_index, EMBEDDING_DIM)</span>
<span id="cb10-35"></span>
<span id="cb10-36"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Now you can use this embedding_matrix in your model, for example:</span></span>
<span id="cb10-37"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># model.add(Embedding(vocab_size, EMBEDDING_DIM, </span></span>
<span id="cb10-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#                     weights=[embedding_matrix], </span></span>
<span id="cb10-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#                     input_length=MAX_SEQUENCE_LENGTH, </span></span>
<span id="cb10-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#                     trainable=False))</span></span></code></pre></div>
</details>
</div>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>At this point you should have cleaned your text data, tokenized it, created padded sequences for the tokens, and then used pre-trained word embeddings to vectorize and find relationships within the data. Now you can feed it into a neural network! I would suggest using a Bidirectional Long Short-Term Memory RNN to train your model as this seems to be a good, safe option when training a model for NLP yourself.</p>
<p>There’s a lot to be done when trying to process text for NLP, and now you know how to turn natural language into computer language! One that would then have to be turned from numbers into the actual computer’s language… Anyways, go train a custom model! Natural language processing is everywhere in the world now, and has great applications in literally everything. If you have ever made a stock trading bot where you use machine learning to analyze trends within numeric data to create predictions, you can actually use NLP to review articles of companies and create sentiment analysis to determine if the stock will change. Nevertheless, remember to preprocess all text until it’s as bare as it can get, and your model will be happy!</p>
<p>Side note, I believe that because of the creation of transformers, most recurrent neural networks (yes, even the better optimized ones) aren’t nearly as good as transformers when it comes to pattern recognition and memorization of text. The transformer models that are currently out for consumer use like Llama 3, GPT-4o, Claude 3, etc. are all trained with billions of dollars so they work very, VERY well. You know who doesn’t have billions of dollars? Probably you (I’m sorry), so generally using a pre-trained transformer model is the way to go if you want to do any projects involving NLP. You can even fine-tune one of these models so it can perform better at a specific task. I think it’s good to know the different core neural networks before tackling something like a transformer, but transformers are kind of the way to go now. You can thank NVIDIA for that.</p>
<hr>
</section>
<section id="support" class="level1 unlisted">
<h1 class="unlisted">Support <i class="fa-solid fa-heart"></i></h1>
<p>You’ve reached the end of my blog post! 🎉🎉🎉<br>
If you learned something and would like to support me, feel free to buy me a coffee :)</p>
<script type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="coreymiichaud" data-color="#FFDD00" data-emoji="" data-font="Poppins" data-text="Buy me a coffee" data-outline-color="#000000" data-font-color="#000000" data-coffee-color="#ffffff"></script>
</section>
<section id="comments" class="level1 unlisted">
<h1 class="unlisted">Comments</h1>
<script src="https://utteranc.es/client.js" repo="coreymichaud/coreymichaud.github.io" issue-term="url" theme="github-light" crossorigin="anonymous" async="">
</script>


</section>

 ]]></description>
  <category>Deep Learning</category>
  <category>NLP</category>
  <category>Python</category>
  <guid>https://coreymichaud.github.io/blog/Text-Preprocessing-NLP/</guid>
  <pubDate>Wed, 24 Jul 2024 04:00:00 GMT</pubDate>
</item>
</channel>
</rss>
