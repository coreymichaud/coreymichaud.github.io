[
  {
    "objectID": "posts/16/index.html",
    "href": "posts/16/index.html",
    "title": "Test Post",
    "section": "",
    "text": "Hello to my blog post!\n\n\n\nCitationBibTeX citation:@online{michaud2024,\n  author = {Michaud, Corey},\n  title = {Test {Post}},\n  date = {2024-06-25},\n  url = {https://github.com/coreymichaud},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMichaud, Corey. 2024. ‚ÄúTest Post.‚Äù June 25, 2024. https://github.com/coreymichaud."
  },
  {
    "objectID": "posts/14/index.html",
    "href": "posts/14/index.html",
    "title": "Test Post",
    "section": "",
    "text": "Hello to my blog post!\n\n\n\nCitationBibTeX citation:@online{michaud2024,\n  author = {Michaud, Corey},\n  title = {Test {Post}},\n  date = {2024-06-25},\n  url = {https://github.com/coreymichaud},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMichaud, Corey. 2024. ‚ÄúTest Post.‚Äù June 25, 2024. https://github.com/coreymichaud."
  },
  {
    "objectID": "posts/12/index.html",
    "href": "posts/12/index.html",
    "title": "Test Post",
    "section": "",
    "text": "Hello to my blog post!\n\n\n\nCitationBibTeX citation:@online{michaud2024,\n  author = {Michaud, Corey},\n  title = {Test {Post}},\n  date = {2024-06-25},\n  url = {https://github.com/coreymichaud},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMichaud, Corey. 2024. ‚ÄúTest Post.‚Äù June 25, 2024. https://github.com/coreymichaud."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Corey Michaud",
    "section": "",
    "text": "Hey!\nMy name‚Äôs Corey Michaud. I recently graduated from the University of Central Florida with a B.S. in Statistics. I have a passion for using statistics, along with coding, to solve real-world problems and create visualizations to better understand and explain data.\n\n\nEducation\nUniversity of Central Florida | Orlando, Florida\nB.S. in Statistics | Aug.¬†2020 - May 2024\n\n\nSkills\nProgramming/Scripting Languages: Python, R, SQL, HTML5, CSS3\nData Visualization: Tableau, Power BI, ggplot2, seaborn\nTools: Excel, Git, SPSS"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Education\nI graduated from the University of Central Florida in Spring of 2024 with a Bachelors of Science in Statistics. I majored in Statistics because throughout high school I was pretty good at math, and when I took AP Statistics I felt like it came naturally to me. Before I had decided, I ‚Äúdecided‚Äù on a new major every month in High School until I landed on statistics, and I‚Äôm glad I chose it.\n\nDuring my time at UCF, I was a part of three clubs: The Association of Computing Machine, Knight Hacks, and AI@UCF. Through these clubs I was able to hone my coding skills and learn about different subjects within machine learning. These clubs allowed me to attend seminars on different fields within computer science and I got hands-on experience with a number of algorithms. Knight Hacks holds one of the largest Florida Hackathons each year, and I was able to attend it for multiple times where I had to make small projects under a time constraint and constant pressure.\nCourses that I have taken include statistical methods, statistical theory, nonparametric statistics, calculus, linear algebra, machine learning, and time series. These have all helped me grow my knowledge of statistics and machine learning and apply it to case studies and numerous projects. I have covered other areas like Bayesian statistics and mathematical methods for artificial intelligence, but these have been spread out through some of my classes.\n\n\n\n Skills\nFor coding, I mainly have used Python and R for machine learning, and R I have used the most for also conducting statistical tests. For R, I am able to create visualizations using ggplot, and using different libraries I can do machine learning functions to solve problems within data. For Python, I have used matplotlib and seaborn for data visualization, and I have used sci-kit learn for machine learning. Besides sci-kit learn, I have used Keras and TensorFlow for a natural language processing project, but I want to learn more about both languages, and hopefully PyTorch soon. For communicating with databases, I use SQL and have used SQLite and PostgreSQL for database practice.\nData visualization has always interested me since I made my first ‚Äúpretty‚Äù plot using ggplot in R. Since then, I have gotten a lot better in R and Python, but now I am focusing a lot on Tableau and Power BI for their interactive dashboards. You can show a lot more data with an interactive dashboard than a static one, so I have been creating many dashboards to be as powerful as they can.\nFeel free to check out my projects tab where I showcase some of them! If you want to check out more, or the source code, then be sure to click on the GitHub icon in the navigation bar.\n\n\n\n Hobbies\nWhen I‚Äôm not trying to learn new things, I like to play video games. Minecraft is an oldie but a goodie, and I sometimes like to play Hearthstone because you can multitask while playing the battlegrounds mode. I love watching movies, even ones people say are bad, but I especially like watching them in a movie theater. I feel like it‚Äôs a lot more immersive and fun that way.\n\nI‚Äôm not sure if this counts as a hobby, but exploring new areas excites me. Everything is new and interesting, and you get to feel what it‚Äôs like to live in that area. When I still lived with my family, we would travel a lot and I got to experience national parks, loud cities, and nature that I don‚Äôt get to experience in Florida. One thing I‚Äôve learned recently is Florida has a lot of natural springs and to me, that feels like traveling because they‚Äôre far from where I live, and they all feel different. Yes, they all have water to swim and kayak in, but the surrounding areas are unique in their own ways.\n\n\n\n Cats\n \nMy girlfriend, Kristina, and I have 2 cats. A cranky, 7 year old tabby named Gnocchi (left), and a super hungry 2 year old calico named Ube (right). Gnocchi is a difficult cat who likes to decide that she doesn‚Äôt like her fancy wet food anymore, and request different food. She also happens to be a yapper if you don‚Äôt give her enough attention, so she gets played with a lot. Ube, on the other hand, is a purr-fect cat. She plays with toys and whatever random wrappers she can find, and likes to cuddle. The one thing about Ube is she can eat, eat, eat. Take her to a buffet and she could probably clean the whole place out. ¬†\nGnocchi was my first cat I‚Äôve gotten, and she happens to also be the first pet I‚Äôve ever gotten, besides a few fish when I was little. She taught me how to become more responsible for things other than myself, and helped me make better daily routines so everything I do becomes more efficient."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "The Statosphere",
    "section": "",
    "text": "Welcome to my blog, The Statosphere. Currently, this is a place where I can write while I do a lot of self-study on, but not limited to, statistics, machine learning, and various fields of mathematics. Hopefully by writing in a bloggy way, I can help myself learn while teaching you something new or interesting. So put your reading glasses on and get ready to enter The Statosphere.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n¬†\n\n\nInsert title\n\n\nCorey Michaud\n\n\n\n\nJun 27, 2024\n\n\nThe American Industrial Revolution\n\n\nCorey Michaud\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/06-25-2024-Test-Post/index.html",
    "href": "posts/06-25-2024-Test-Post/index.html",
    "title": "Test Post",
    "section": "",
    "text": "Hello to my blog post!\n\n\n\nCitationBibTeX citation:@online{michaud2024,\n  author = {Michaud, Corey},\n  title = {Test {Post}},\n  date = {2024-06-25},\n  url = {https://github.com/coreymichaud},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMichaud, Corey. 2024. ‚ÄúTest Post.‚Äù June 25, 2024. https://github.com/coreymichaud."
  },
  {
    "objectID": "posts/13/index.html",
    "href": "posts/13/index.html",
    "title": "Test Post",
    "section": "",
    "text": "Hello to my blog post!\n\n\n\nCitationBibTeX citation:@online{michaud2024,\n  author = {Michaud, Corey},\n  title = {Test {Post}},\n  date = {2024-06-25},\n  url = {https://github.com/coreymichaud},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMichaud, Corey. 2024. ‚ÄúTest Post.‚Äù June 25, 2024. https://github.com/coreymichaud."
  },
  {
    "objectID": "posts/15/index.html",
    "href": "posts/15/index.html",
    "title": "Test Post",
    "section": "",
    "text": "Hello to my blog post!\n\n\n\nCitationBibTeX citation:@online{michaud2024,\n  author = {Michaud, Corey},\n  title = {Test {Post}},\n  date = {2024-06-25},\n  url = {https://github.com/coreymichaud},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMichaud, Corey. 2024. ‚ÄúTest Post.‚Äù June 25, 2024. https://github.com/coreymichaud."
  },
  {
    "objectID": "posts/Blog Template/index.html",
    "href": "posts/Blog Template/index.html",
    "title": "Insert title",
    "section": "",
    "text": "Hello to my blog post!\n\n\n\nCitationBibTeX citation:@online{michaud,\n  author = {Michaud, Corey},\n  title = {Insert Title},\n  url = {https://coreymichaud.github.io/nameofthisblogsfolder/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMichaud, Corey. n.d. ‚ÄúInsert Title.‚Äù https://coreymichaud.github.io/nameofthisblogsfolder/."
  },
  {
    "objectID": "blog/16/index.html",
    "href": "blog/16/index.html",
    "title": "Test Post",
    "section": "",
    "text": "Hello to my blog post!\n\n\n\nCitationBibTeX citation:@online{michaud2024,\n  author = {Michaud, Corey},\n  title = {Test {Post}},\n  date = {2024-06-25},\n  url = {https://github.com/coreymichaud},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMichaud, Corey. 2024. ‚ÄúTest Post.‚Äù June 25, 2024. https://github.com/coreymichaud."
  },
  {
    "objectID": "blog/14/index.html",
    "href": "blog/14/index.html",
    "title": "Test Post",
    "section": "",
    "text": "Hello to my blog post!\n\n\n\nCitationBibTeX citation:@online{michaud2024,\n  author = {Michaud, Corey},\n  title = {Test {Post}},\n  date = {2024-06-25},\n  url = {https://github.com/coreymichaud},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMichaud, Corey. 2024. ‚ÄúTest Post.‚Äù June 25, 2024. https://github.com/coreymichaud."
  },
  {
    "objectID": "blog/12/index.html",
    "href": "blog/12/index.html",
    "title": "Test Post",
    "section": "",
    "text": "Hello to my blog post!\n\n\n\nCitationBibTeX citation:@online{michaud2024,\n  author = {Michaud, Corey},\n  title = {Test {Post}},\n  date = {2024-06-25},\n  url = {https://github.com/coreymichaud},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMichaud, Corey. 2024. ‚ÄúTest Post.‚Äù June 25, 2024. https://github.com/coreymichaud."
  },
  {
    "objectID": "blog/06-25-2024-Test-Post/index.html",
    "href": "blog/06-25-2024-Test-Post/index.html",
    "title": "Test Post",
    "section": "",
    "text": "Hello to my blog post!\n\n\n\nCitationBibTeX citation:@online{michaud2024,\n  author = {Michaud, Corey},\n  title = {Test {Post}},\n  date = {2024-06-25},\n  url = {https://github.com/coreymichaud},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMichaud, Corey. 2024. ‚ÄúTest Post.‚Äù June 25, 2024. https://github.com/coreymichaud."
  },
  {
    "objectID": "blog/13/index.html",
    "href": "blog/13/index.html",
    "title": "Test Post",
    "section": "",
    "text": "Hello to my blog post!\n\n\n\nCitationBibTeX citation:@online{michaud2024,\n  author = {Michaud, Corey},\n  title = {Test {Post}},\n  date = {2024-06-25},\n  url = {https://github.com/coreymichaud},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMichaud, Corey. 2024. ‚ÄúTest Post.‚Äù June 25, 2024. https://github.com/coreymichaud."
  },
  {
    "objectID": "blog/15/index.html",
    "href": "blog/15/index.html",
    "title": "Test Post",
    "section": "",
    "text": "Hello to my blog post!\n\n\n\nCitationBibTeX citation:@online{michaud2024,\n  author = {Michaud, Corey},\n  title = {Test {Post}},\n  date = {2024-06-25},\n  url = {https://github.com/coreymichaud},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMichaud, Corey. 2024. ‚ÄúTest Post.‚Äù June 25, 2024. https://github.com/coreymichaud."
  },
  {
    "objectID": "blog/06-27-2024-Industrial-Revolution/index.html",
    "href": "blog/06-27-2024-Industrial-Revolution/index.html",
    "title": "The American Industrial Revolution",
    "section": "",
    "text": "The American Industrial Revolution, spanning roughly from the late 18th century to the mid-19th century, was a period of profound economic, social, and technological transformation. This era marked the transition from agrarian economies to industrialized and urbanized societies. Several key factors contributed to this transformation, each playing a pivotal role in reshaping the United States.\n\n\n\n\nThe introduction of mechanized textile production was a significant factor. Samuel Slater, known as the ‚ÄúFather of the American Industrial Revolution,‚Äù brought British textile technology to America, establishing the first successful textile mill in Pawtucket, Rhode Island, in 1793. The development of steam engines by innovators like James Watt revolutionized transportation and manufacturing. Steam-powered locomotives and boats facilitated faster movement of goods and people, effectively shrinking the vast American landscape. Pioneered by Eli Whitney, the concept of interchangeable parts in manufacturing standardized production and significantly increased efficiency, laying the groundwork for mass production.\n\n\n\nThe construction of canals, such as the Erie Canal (completed in 1825), and the expansion of the railroad network connected regional markets and resources, lowering transportation costs and spurring economic growth. Improved roadways facilitated better movement of goods and people within the country, promoting regional trade and commerce.\n\n\n\nThe population boom, fueled by both natural increase and immigration, provided a steady supply of labor for factories and industrial enterprises. Cities grew around industrial hubs, with places like Lowell, Massachusetts, becoming models of industrial communities. Urbanization brought about new social dynamics, including the rise of a distinct working class.\n\n\n\nThe establishment of a robust banking system provided the necessary capital for industrial ventures. The availability of credit and investment opportunities spurred entrepreneurial activities and industrial expansion. Protective tariffs and supportive government policies helped nurture American industries by shielding them from foreign competition and encouraging domestic production.\n\n\n\n\n\n\nThe American Industrial Revolution led to unprecedented economic growth. The shift from agrarian to industrial economies increased productivity, diversified the economy, and boosted the national GDP. The rise of factories created numerous jobs, attracting rural populations to urban centers and fostering a consumer culture driven by new goods and services.\n\n\n\nThe harsh working conditions in factories gave rise to labor movements advocating for better wages, working hours, and conditions. This period saw the emergence of trade unions and labor strikes. Women and children played significant roles in the workforce, particularly in textile mills. This involvement began shifting traditional gender roles and highlighted the need for labor reforms.\n\n\n\nIndustrialization brought significant environmental changes, including deforestation, pollution, and changes in land use. The exploitation of natural resources raised concerns about sustainability and environmental degradation.\n\n\n\nThe industrial revolution spurred technological innovation and scientific discovery. Advances in metallurgy, chemistry, and engineering had far-reaching effects beyond industry, influencing agriculture, medicine, and everyday life.\n\n\n\n\nThe American Industrial Revolution laid the foundation for the United States‚Äô emergence as a global economic power. It transformed the social fabric, economic landscape, and technological capabilities of the nation. The lessons learned from this era, including the importance of innovation, infrastructure, labor rights, and environmental stewardship, continue to resonate in contemporary discussions about economic development and industrialization.\nWhile the Industrial Revolution brought about significant progress and prosperity, it also posed challenges that required societal adaptation and regulatory measures. Understanding this complex period is crucial for appreciating the dynamics of modern industrial economies and addressing the ongoing impacts of industrialization in the 21st century."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Alzheimer‚Äôs Detection\n\n\n\n\n\n\nPython\n\n\nMachine Learning\n\n\n\nThis is a python notebook where I analyze the DAWRIN dataset to detect Alzheimer‚Äôs in an individual‚Äôs handwriting. To classify, I used random forest in Python.\n\n\n\n\n\nJul 31, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Alzheimer‚Äôs Detection",
    "section": "",
    "text": "Source Code\nHi"
  },
  {
    "objectID": "projects/alzheimers-detection/index.html",
    "href": "projects/alzheimers-detection/index.html",
    "title": "Alzheimer‚Äôs Detection",
    "section": "",
    "text": "Source Code\n\nBackground\nAlzheimer‚Äôs is a type of dementia that affects memory, thinking, and behavior. It is caused by increasing age, and primarily affects people above the age of 65. As a person develops Alzheimer‚Äôs, it progressively becomes worse where the individual can lose the ability to carry a conversation or even take care of themselves. After diagnosis, a person can expect to live on average between 4 to 8 years, but on better cases up to 20 years. Luckily there is medication to help slow the worsening of Alzheimer‚Äôs, but nothing to completely prevent it from happening.\nThe data used for the detection of Alzheimer‚Äôs through handwriting comes from the DARWIN (Diagnosis AlzheimeR WIth haNdwriting) dataset. This dataset is made up of 174 individual‚Äôs handwriting where roughly half are Alzheimer‚Äôs patients (P), and healthy people (H). The handwriting was taken through tasks the individuals were asked to do, and then variables like time in air were measured. In doing so, the creators of the DARWIN dataset provided us the materials we need to use machine learning techniques to detect the early stages of Alzheimer‚Äôs through handwriting. Some of the tasks recorded were connecting points through lines and copying phrases that were written in front of them, all of which test different parts of the brain.\nUsing handwriting data, I will use a random forest classifier to predict whether an individual has Alzheimer‚Äôs or not. The goal is for future handwriting data to be inserted and accurately predict the correct diagnosis, saving the individual time to get treatment to slow down the process.\nAlzheimers detection dataset obtained from https://www.kaggle.com/datasets/taeefnajib/handwriting-data-to-detect-alzheimers-disease.\n\n# Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Loading data\nalz = pd.read_csv(\"alzheimers.csv\")\n\n\n\nExploratory Data Analysis\n\n# First 5 rows of data\nalz.head(5)\n\n\n\n\n\n\n\n\nID\nair_time1\ndisp_index1\ngmrt_in_air1\ngmrt_on_paper1\nmax_x_extension1\nmax_y_extension1\nmean_acc_in_air1\nmean_acc_on_paper1\nmean_gmrt1\n...\nmean_jerk_in_air25\nmean_jerk_on_paper25\nmean_speed_in_air25\nmean_speed_on_paper25\nnum_of_pendown25\npaper_time25\npressure_mean25\npressure_var25\ntotal_time25\nclass\n\n\n\n\n0\nid_1\n5160\n0.000013\n120.804174\n86.853334\n957\n6601\n0.361800\n0.217459\n103.828754\n...\n0.141434\n0.024471\n5.596487\n3.184589\n71\n40120\n1749.278166\n296102.7676\n144605\nP\n\n\n1\nid_2\n51980\n0.000016\n115.318238\n83.448681\n1694\n6998\n0.272513\n0.144880\n99.383459\n...\n0.049663\n0.018368\n1.665973\n0.950249\n129\n126700\n1504.768272\n278744.2850\n298640\nP\n\n\n2\nid_3\n2600\n0.000010\n229.933997\n172.761858\n2333\n5802\n0.387020\n0.181342\n201.347928\n...\n0.178194\n0.017174\n4.000781\n2.392521\n74\n45480\n1431.443492\n144411.7055\n79025\nP\n\n\n3\nid_4\n2130\n0.000010\n369.403342\n183.193104\n1756\n8159\n0.556879\n0.164502\n276.298223\n...\n0.113905\n0.019860\n4.206746\n1.613522\n123\n67945\n1465.843329\n230184.7154\n181220\nP\n\n\n4\nid_5\n2310\n0.000007\n257.997131\n111.275889\n987\n4732\n0.266077\n0.145104\n184.636510\n...\n0.121782\n0.020872\n3.319036\n1.680629\n92\n37285\n1841.702561\n158290.0255\n72575\nP\n\n\n\n\n5 rows √ó 452 columns\n\n\n\n\n# Shape of data\nalz.shape\n\n(174, 452)\n\n\n\n# Data information\nalz.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 174 entries, 0 to 173\nColumns: 452 entries, ID to class\ndtypes: float64(300), int64(150), object(2)\nmemory usage: 614.6+ KB\n\n\n\n# Checking for object column names\nalz.select_dtypes(include = \"object\").columns.tolist()\n\n['ID', 'class']\n\n\n\n# Checking for missing values\nalz.isna().sum() # No NA values\n\nID                 0\nair_time1          0\ndisp_index1        0\ngmrt_in_air1       0\ngmrt_on_paper1     0\n                  ..\npaper_time25       0\npressure_mean25    0\npressure_var25     0\ntotal_time25       0\nclass              0\nLength: 452, dtype: int64\n\n\n\n\nFeature Engineering\n\n# Removing ID column\nalz = alz.drop(\"ID\", axis = 1)\nalz.head(5)\n\n\n\n\n\n\n\n\nair_time1\ndisp_index1\ngmrt_in_air1\ngmrt_on_paper1\nmax_x_extension1\nmax_y_extension1\nmean_acc_in_air1\nmean_acc_on_paper1\nmean_gmrt1\nmean_jerk_in_air1\n...\nmean_jerk_in_air25\nmean_jerk_on_paper25\nmean_speed_in_air25\nmean_speed_on_paper25\nnum_of_pendown25\npaper_time25\npressure_mean25\npressure_var25\ntotal_time25\nclass\n\n\n\n\n0\n5160\n0.000013\n120.804174\n86.853334\n957\n6601\n0.361800\n0.217459\n103.828754\n0.051836\n...\n0.141434\n0.024471\n5.596487\n3.184589\n71\n40120\n1749.278166\n296102.7676\n144605\nP\n\n\n1\n51980\n0.000016\n115.318238\n83.448681\n1694\n6998\n0.272513\n0.144880\n99.383459\n0.039827\n...\n0.049663\n0.018368\n1.665973\n0.950249\n129\n126700\n1504.768272\n278744.2850\n298640\nP\n\n\n2\n2600\n0.000010\n229.933997\n172.761858\n2333\n5802\n0.387020\n0.181342\n201.347928\n0.064220\n...\n0.178194\n0.017174\n4.000781\n2.392521\n74\n45480\n1431.443492\n144411.7055\n79025\nP\n\n\n3\n2130\n0.000010\n369.403342\n183.193104\n1756\n8159\n0.556879\n0.164502\n276.298223\n0.090408\n...\n0.113905\n0.019860\n4.206746\n1.613522\n123\n67945\n1465.843329\n230184.7154\n181220\nP\n\n\n4\n2310\n0.000007\n257.997131\n111.275889\n987\n4732\n0.266077\n0.145104\n184.636510\n0.037528\n...\n0.121782\n0.020872\n3.319036\n1.680629\n92\n37285\n1841.702561\n158290.0255\n72575\nP\n\n\n\n\n5 rows √ó 451 columns\n\n\n\n\n# Converting class to numeric\nalz[\"class\"] = alz[\"class\"].replace({'P': 1, 'H': 0})\nalz[\"class\"]\n\nC:\\Users\\cor3y\\AppData\\Local\\Temp\\ipykernel_6484\\2961317950.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  alz[\"class\"] = alz[\"class\"].replace({'P': 1, 'H': 0})\n\n\n0      1\n1      1\n2      1\n3      1\n4      1\n      ..\n169    0\n170    0\n171    0\n172    0\n173    0\nName: class, Length: 174, dtype: int64\n\n\n\n\nModel Training\n\nfrom sklearn.model_selection import train_test_split\n\n# Separating features from target\nX = alz.drop(columns=[\"class\"])\ny = alz[\"class\"]\n\n# Training data with a 70/30 split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state = 42)\n\n\n# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import plot_tree\n\n# Creating random forest pipeline with scaled data\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('classifier', RandomForestClassifier(random_state = 42, max_samples = 0.6, min_samples_leaf = 2))\n])\n\n# Fitting pipeline\npipe.fit(X_train, y_train)\n\n# Predicting target values\ny_pred = pipe.predict(X_test)\n\n\n# Plotting first tree in the random forest\ntree_viz = pipe.named_steps['classifier'].estimators_[0]\n\nfig, ax = plt.subplots(figsize = (15, 10))\n\nplot_tree(tree_viz, feature_names = alz.columns.tolist(), class_names = [\"Patient\", \"Healthy\"], filled = True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Plotting fiftieth tree in the random forest\ntree_viz = pipe.named_steps['classifier'].estimators_[49]\n\nfig, ax = plt.subplots(figsize = (15, 10))\n\nplot_tree(tree_viz, feature_names = alz.columns.tolist(), class_names = [\"Patient\", \"Healthy\"], filled = True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nResults\n\nfrom sklearn.metrics import f1_score\n\n# F1 score is high so this random forest model is a good predictor of the target\nf1 = f1_score(y_test, y_pred)\nprint(\"F1 Score:\", f1)\n\nF1 Score: 0.9019607843137255\n\n\n\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\n# False positive and true positive rates\nfpr, tpr, _ = roc_curve(y_test, y_pred)\n\n# AUC\nauc = roc_auc_score(y_test, y_pred)\n\n# Plotting ROC curve\nfig, ax = plt.subplots()\n\nax.plot(fpr, tpr, color = 'darkorange', lw = 2, label = 'ROC curve (AUC = {:.2f})'.format(auc))\nax.plot([0, 1], [0, 1], color = 'navy', lw = 2, linestyle = '--')\n\nax.set_xlim([0.0, 1.0])\nax.set_ylim([0.0, 1.05])\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.set_title('Receiver Operating Characteristic (ROC) Curve')\nax.legend(loc = \"lower right\")\n\nsns.despine()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom sklearn.metrics import confusion_matrix\n\n# Creating confusion matrix\nconf_matrix = confusion_matrix(y_test,y_pred)\n\n# Plotting confusion matrix \nfig, ax = plt.subplots()\n\nsns.heatmap(conf_matrix,\n            annot = True,\n            fmt = 'g',\n            xticklabels = ['Positive', 'Negative'],\n            yticklabels = ['Positive', 'Negative'],\n            cmap = [\"Red\", \"Green\", \"Red\", \"Green\"],\n            cbar = False,\n            annot_kws = {\"size\": 20},\n            ax = ax)\n\nax.set_title('Confusion Matrix', fontsize = 17)\nax.set_ylabel('Prediction', fontsize = 13)\nax.set_xlabel('Actual', fontsize = 13)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Creating TP/FP/TN/FN\nTP = conf_matrix[1, 1]\nFN = conf_matrix[1, 0]\nTN = conf_matrix[0, 0]\nFP = conf_matrix[0, 1]\n\n# Printing results of predictions\naccuracy = (TP + TN) / (TP + TN + FP + FN)\nprecision = (TP) / (TP + FP)\nsensitivity = TP / (TP + FN)\nspecificity = TN / (TN + FP)\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Sensitivity:\", sensitivity)\nprint(\"Specificity:\", specificity)\n\nAccuracy: 0.9056603773584906\nPrecision: 0.8846153846153846\nSensitivity: 0.92\nSpecificity: 0.8928571428571429"
  },
  {
    "objectID": "blog/06-27-2024-Industrial-Revolution/index.html#key-drivers-and-innovations",
    "href": "blog/06-27-2024-Industrial-Revolution/index.html#key-drivers-and-innovations",
    "title": "The American Industrial Revolution",
    "section": "",
    "text": "The introduction of mechanized textile production was a significant factor. Samuel Slater, known as the ‚ÄúFather of the American Industrial Revolution,‚Äù brought British textile technology to America, establishing the first successful textile mill in Pawtucket, Rhode Island, in 1793. The development of steam engines by innovators like James Watt revolutionized transportation and manufacturing. Steam-powered locomotives and boats facilitated faster movement of goods and people, effectively shrinking the vast American landscape. Pioneered by Eli Whitney, the concept of interchangeable parts in manufacturing standardized production and significantly increased efficiency, laying the groundwork for mass production.\n\n\n\nThe construction of canals, such as the Erie Canal (completed in 1825), and the expansion of the railroad network connected regional markets and resources, lowering transportation costs and spurring economic growth. Improved roadways facilitated better movement of goods and people within the country, promoting regional trade and commerce.\n\n\n\nThe population boom, fueled by both natural increase and immigration, provided a steady supply of labor for factories and industrial enterprises. Cities grew around industrial hubs, with places like Lowell, Massachusetts, becoming models of industrial communities. Urbanization brought about new social dynamics, including the rise of a distinct working class.\n\n\n\nThe establishment of a robust banking system provided the necessary capital for industrial ventures. The availability of credit and investment opportunities spurred entrepreneurial activities and industrial expansion. Protective tariffs and supportive government policies helped nurture American industries by shielding them from foreign competition and encouraging domestic production."
  },
  {
    "objectID": "blog/06-27-2024-Industrial-Revolution/index.html#economic-and-social-impact",
    "href": "blog/06-27-2024-Industrial-Revolution/index.html#economic-and-social-impact",
    "title": "The American Industrial Revolution",
    "section": "",
    "text": "The American Industrial Revolution led to unprecedented economic growth. The shift from agrarian to industrial economies increased productivity, diversified the economy, and boosted the national GDP. The rise of factories created numerous jobs, attracting rural populations to urban centers and fostering a consumer culture driven by new goods and services.\n\n\n\nThe harsh working conditions in factories gave rise to labor movements advocating for better wages, working hours, and conditions. This period saw the emergence of trade unions and labor strikes. Women and children played significant roles in the workforce, particularly in textile mills. This involvement began shifting traditional gender roles and highlighted the need for labor reforms.\n\n\n\nIndustrialization brought significant environmental changes, including deforestation, pollution, and changes in land use. The exploitation of natural resources raised concerns about sustainability and environmental degradation.\n\n\n\nThe industrial revolution spurred technological innovation and scientific discovery. Advances in metallurgy, chemistry, and engineering had far-reaching effects beyond industry, influencing agriculture, medicine, and everyday life."
  },
  {
    "objectID": "blog/06-27-2024-Industrial-Revolution/index.html#legacy",
    "href": "blog/06-27-2024-Industrial-Revolution/index.html#legacy",
    "title": "The American Industrial Revolution",
    "section": "",
    "text": "The American Industrial Revolution laid the foundation for the United States‚Äô emergence as a global economic power. It transformed the social fabric, economic landscape, and technological capabilities of the nation. The lessons learned from this era, including the importance of innovation, infrastructure, labor rights, and environmental stewardship, continue to resonate in contemporary discussions about economic development and industrialization.\nWhile the Industrial Revolution brought about significant progress and prosperity, it also posed challenges that required societal adaptation and regulatory measures. Understanding this complex period is crucial for appreciating the dynamics of modern industrial economies and addressing the ongoing impacts of industrialization in the 21st century."
  },
  {
    "objectID": "blog/06-27-2024-Industrial-Revolution/index.html#support",
    "href": "blog/06-27-2024-Industrial-Revolution/index.html#support",
    "title": "The American Industrial Revolution",
    "section": "",
    "text": "You‚Äôve reached the end of my blog post! üéâüéâüéâ\nIf you learned something and would like to support me, feel free to buy me a coffee :)"
  },
  {
    "objectID": "projects/alzheimers-detection - Copy/index.html",
    "href": "projects/alzheimers-detection - Copy/index.html",
    "title": "Alzheimer‚Äôs Detection",
    "section": "",
    "text": "Source Code\n\nBackground\nAlzheimer‚Äôs is a type of dementia that affects memory, thinking, and behavior. It is caused by increasing age, and primarily affects people above the age of 65. As a person develops Alzheimer‚Äôs, it progressively becomes worse where the individual can lose the ability to carry a conversation or even take care of themselves. After diagnosis, a person can expect to live on average between 4 to 8 years, but on better cases up to 20 years. Luckily there is medication to help slow the worsening of Alzheimer‚Äôs, but nothing to completely prevent it from happening.\nThe data used for the detection of Alzheimer‚Äôs through handwriting comes from the DARWIN (Diagnosis AlzheimeR WIth haNdwriting) dataset. This dataset is made up of 174 individual‚Äôs handwriting where roughly half are Alzheimer‚Äôs patients (P), and healthy people (H). The handwriting was taken through tasks the individuals were asked to do, and then variables like time in air were measured. In doing so, the creators of the DARWIN dataset provided us the materials we need to use machine learning techniques to detect the early stages of Alzheimer‚Äôs through handwriting. Some of the tasks recorded were connecting points through lines and copying phrases that were written in front of them, all of which test different parts of the brain.\nUsing handwriting data, I will use a random forest classifier to predict whether an individual has Alzheimer‚Äôs or not. The goal is for future handwriting data to be inserted and accurately predict the correct diagnosis, saving the individual time to get treatment to slow down the process.\nAlzheimers detection dataset obtained from https://www.kaggle.com/datasets/taeefnajib/handwriting-data-to-detect-alzheimers-disease.\n\n# Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Loading data\nalz = pd.read_csv(\"alzheimers.csv\")\n\n\n\nExploratory Data Analysis\n\n# First 5 rows of data\nalz.head(5)\n\n\n\n\n\n\n\n\nID\nair_time1\ndisp_index1\ngmrt_in_air1\ngmrt_on_paper1\nmax_x_extension1\nmax_y_extension1\nmean_acc_in_air1\nmean_acc_on_paper1\nmean_gmrt1\n...\nmean_jerk_in_air25\nmean_jerk_on_paper25\nmean_speed_in_air25\nmean_speed_on_paper25\nnum_of_pendown25\npaper_time25\npressure_mean25\npressure_var25\ntotal_time25\nclass\n\n\n\n\n0\nid_1\n5160\n0.000013\n120.804174\n86.853334\n957\n6601\n0.361800\n0.217459\n103.828754\n...\n0.141434\n0.024471\n5.596487\n3.184589\n71\n40120\n1749.278166\n296102.7676\n144605\nP\n\n\n1\nid_2\n51980\n0.000016\n115.318238\n83.448681\n1694\n6998\n0.272513\n0.144880\n99.383459\n...\n0.049663\n0.018368\n1.665973\n0.950249\n129\n126700\n1504.768272\n278744.2850\n298640\nP\n\n\n2\nid_3\n2600\n0.000010\n229.933997\n172.761858\n2333\n5802\n0.387020\n0.181342\n201.347928\n...\n0.178194\n0.017174\n4.000781\n2.392521\n74\n45480\n1431.443492\n144411.7055\n79025\nP\n\n\n3\nid_4\n2130\n0.000010\n369.403342\n183.193104\n1756\n8159\n0.556879\n0.164502\n276.298223\n...\n0.113905\n0.019860\n4.206746\n1.613522\n123\n67945\n1465.843329\n230184.7154\n181220\nP\n\n\n4\nid_5\n2310\n0.000007\n257.997131\n111.275889\n987\n4732\n0.266077\n0.145104\n184.636510\n...\n0.121782\n0.020872\n3.319036\n1.680629\n92\n37285\n1841.702561\n158290.0255\n72575\nP\n\n\n\n\n5 rows √ó 452 columns\n\n\n\n\n# Shape of data\nalz.shape\n\n(174, 452)\n\n\n\n# Data information\nalz.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 174 entries, 0 to 173\nColumns: 452 entries, ID to class\ndtypes: float64(300), int64(150), object(2)\nmemory usage: 614.6+ KB\n\n\n\n# Checking for object column names\nalz.select_dtypes(include = \"object\").columns.tolist()\n\n['ID', 'class']\n\n\n\n# Checking for missing values\nalz.isna().sum() # No NA values\n\nID                 0\nair_time1          0\ndisp_index1        0\ngmrt_in_air1       0\ngmrt_on_paper1     0\n                  ..\npaper_time25       0\npressure_mean25    0\npressure_var25     0\ntotal_time25       0\nclass              0\nLength: 452, dtype: int64\n\n\n\n\nFeature Engineering\n\n# Removing ID column\nalz = alz.drop(\"ID\", axis = 1)\nalz.head(5)\n\n\n\n\n\n\n\n\nair_time1\ndisp_index1\ngmrt_in_air1\ngmrt_on_paper1\nmax_x_extension1\nmax_y_extension1\nmean_acc_in_air1\nmean_acc_on_paper1\nmean_gmrt1\nmean_jerk_in_air1\n...\nmean_jerk_in_air25\nmean_jerk_on_paper25\nmean_speed_in_air25\nmean_speed_on_paper25\nnum_of_pendown25\npaper_time25\npressure_mean25\npressure_var25\ntotal_time25\nclass\n\n\n\n\n0\n5160\n0.000013\n120.804174\n86.853334\n957\n6601\n0.361800\n0.217459\n103.828754\n0.051836\n...\n0.141434\n0.024471\n5.596487\n3.184589\n71\n40120\n1749.278166\n296102.7676\n144605\nP\n\n\n1\n51980\n0.000016\n115.318238\n83.448681\n1694\n6998\n0.272513\n0.144880\n99.383459\n0.039827\n...\n0.049663\n0.018368\n1.665973\n0.950249\n129\n126700\n1504.768272\n278744.2850\n298640\nP\n\n\n2\n2600\n0.000010\n229.933997\n172.761858\n2333\n5802\n0.387020\n0.181342\n201.347928\n0.064220\n...\n0.178194\n0.017174\n4.000781\n2.392521\n74\n45480\n1431.443492\n144411.7055\n79025\nP\n\n\n3\n2130\n0.000010\n369.403342\n183.193104\n1756\n8159\n0.556879\n0.164502\n276.298223\n0.090408\n...\n0.113905\n0.019860\n4.206746\n1.613522\n123\n67945\n1465.843329\n230184.7154\n181220\nP\n\n\n4\n2310\n0.000007\n257.997131\n111.275889\n987\n4732\n0.266077\n0.145104\n184.636510\n0.037528\n...\n0.121782\n0.020872\n3.319036\n1.680629\n92\n37285\n1841.702561\n158290.0255\n72575\nP\n\n\n\n\n5 rows √ó 451 columns\n\n\n\n\n# Converting class to numeric\nalz[\"class\"] = alz[\"class\"].replace({'P': 1, 'H': 0})\nalz[\"class\"]\n\nC:\\Users\\cor3y\\AppData\\Local\\Temp\\ipykernel_11244\\2961317950.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  alz[\"class\"] = alz[\"class\"].replace({'P': 1, 'H': 0})\n\n\n0      1\n1      1\n2      1\n3      1\n4      1\n      ..\n169    0\n170    0\n171    0\n172    0\n173    0\nName: class, Length: 174, dtype: int64\n\n\n\n\nModel Training\n\nfrom sklearn.model_selection import train_test_split\n\n# Separating features from target\nX = alz.drop(columns=[\"class\"])\ny = alz[\"class\"]\n\n# Training data with a 70/30 split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state = 42)\n\n\n# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import plot_tree\n\n# Creating random forest pipeline with scaled data\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('classifier', RandomForestClassifier(random_state = 42, max_samples = 0.6, min_samples_leaf = 2))\n])\n\n# Fitting pipeline\npipe.fit(X_train, y_train)\n\n# Predicting target values\ny_pred = pipe.predict(X_test)\n\n\n# Plotting first tree in the random forest\ntree_viz = pipe.named_steps['classifier'].estimators_[0]\n\nfig, ax = plt.subplots(figsize = (15, 10))\n\nplot_tree(tree_viz, feature_names = alz.columns.tolist(), class_names = [\"Patient\", \"Healthy\"], filled = True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Plotting fiftieth tree in the random forest\ntree_viz = pipe.named_steps['classifier'].estimators_[49]\n\nfig, ax = plt.subplots(figsize = (15, 10))\n\nplot_tree(tree_viz, feature_names = alz.columns.tolist(), class_names = [\"Patient\", \"Healthy\"], filled = True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nResults\n\nfrom sklearn.metrics import f1_score\n\n# F1 score is high so this random forest model is a good predictor of the target\nf1 = f1_score(y_test, y_pred)\nprint(\"F1 Score:\", f1)\n\nF1 Score: 0.9019607843137255\n\n\n\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\n# False positive and true positive rates\nfpr, tpr, _ = roc_curve(y_test, y_pred)\n\n# AUC\nauc = roc_auc_score(y_test, y_pred)\n\n# Plotting ROC curve\nfig, ax = plt.subplots()\n\nax.plot(fpr, tpr, color = 'darkorange', lw = 2, label = 'ROC curve (AUC = {:.2f})'.format(auc))\nax.plot([0, 1], [0, 1], color = 'navy', lw = 2, linestyle = '--')\n\nax.set_xlim([0.0, 1.0])\nax.set_ylim([0.0, 1.05])\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.set_title('Receiver Operating Characteristic (ROC) Curve')\nax.legend(loc = \"lower right\")\n\nsns.despine()\n\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom sklearn.metrics import confusion_matrix\n\n# Creating confusion matrix\nconf_matrix = confusion_matrix(y_test,y_pred)\n\n# Plotting confusion matrix \nfig, ax = plt.subplots()\n\nsns.heatmap(conf_matrix,\n            annot = True,\n            fmt = 'g',\n            xticklabels = ['Positive', 'Negative'],\n            yticklabels = ['Positive', 'Negative'],\n            cmap = [\"Red\", \"Green\", \"Red\", \"Green\"],\n            cbar = False,\n            annot_kws = {\"size\": 20},\n            ax = ax)\n\nax.set_title('Confusion Matrix', fontsize = 17)\nax.set_ylabel('Prediction', fontsize = 13)\nax.set_xlabel('Actual', fontsize = 13)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Creating TP/FP/TN/FN\nTP = conf_matrix[1, 1]\nFN = conf_matrix[1, 0]\nTN = conf_matrix[0, 0]\nFP = conf_matrix[0, 1]\n\n# Printing results of predictions\naccuracy = (TP + TN) / (TP + TN + FP + FN)\nprecision = (TP) / (TP + FP)\nsensitivity = TP / (TP + FN)\nspecificity = TN / (TN + FP)\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Sensitivity:\", sensitivity)\nprint(\"Specificity:\", specificity)\n\nAccuracy: 0.9056603773584906\nPrecision: 0.8846153846153846\nSensitivity: 0.92\nSpecificity: 0.8928571428571429"
  }
]